# 零散的知识

## 零拷贝优化

> 原来 8 张图，就可以搞懂「零拷贝」了 - 小林coding的文章 - 知乎
> https://zhuanlan.zhihu.com/p/258513662

### 前置技术说明

1. 没有 DMA 之前
   
   read() -> CPU 发出指令给磁盘 -> 磁盘读到自己的内部缓冲区 -> 中断信号给 CPU -> CPU 负责拷贝到内存中的磁盘缓冲区 -> CPU 负责拷贝到用户进程缓冲区 -> read() 返回

2. DMA
   
   + read() -> OS 将 IO 请求发送给 DMA -> CPU 执行其他任务等待唤醒 -> 将内存中准备好的数据拷贝到用户进程缓冲区 -> read() 返回
   
   + DMA 将 I/O 请求发送给磁盘 -> 磁盘读到自己的内部缓冲区 -> 中断信号给 DMA -> DMA 负责拷贝到内存中的磁盘缓冲区【不占用 CPU 时间】

### 场景：传统的文件传输有多糟糕

如果服务端要提供文件传输的功能，我们能想到的最简单的方式是：将磁盘上的文件读取出来，然后通过网络协议发送给客户端。

数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的 I/O 接口从磁盘读取或写入。一般会需要两个系统调用：

```c++
read(file, tmp_buf, len);
write(socket, tmp_buf, len);
```

![preview](https://pic2.zhimg.com/v2-e3b554661358b18b3f36cc17f0b0c8c1_r.jpg)

首先，期间共发生了 4 次用户态与内核态的上下文切换，还**发生了 4 次数据拷贝**，其中两次是 DMA 的拷贝，**另外两次则是通过 CPU 拷贝的。**

所以，要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数。

### 优化一：mmap + write

文件传输的应用场景中，在用户空间我们并不会对数据「再加工」，所以数据实际上可以不用搬运到用户空间，因此**用户的缓冲区是没有必要存在的**。

可以用 `mmap()` 替换 `read()` 系统调用函数。`mmap()` 系统调用函数会直接把内核缓冲区里的数据「**映射**」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。

![preview](https://pic2.zhimg.com/v2-16ff9ac786b16508711083ed44a8ff79_r.jpg)

- 应用进程调用了 `mmap()` 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；
- 应用进程再调用 `write()`，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；
- 最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。

仍然需要 4 次上下文切换，1 次 CPU 拷贝。

### 优化二：sendfile

在 Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 `sendfile()`，函数形式如下：

```c++
#include <sys/socket.h>
ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
```

它可以替代前面的 `read()` 和 `write()` 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。

![preview](https://pic4.zhimg.com/v2-557b255dbca2fdd3a5a213cbee7df513_r.jpg)

这样就只有 2 次上下文切换，和 3 次数据拷贝（其中一次 CPU 拷贝）。

### 优化三：sendfile + 支持 SG-DMA（DMA 收集） 的网卡

于是，从 Linux 内核 `2.4` 版本开始起，对于支持网卡支持 SG-DMA 技术的情况下， `sendfile()` 系统调用的过程发生了点变化，具体过程如下：

- 第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；
- 第二步，**缓冲区描述符和数据长度传到 socket 缓冲区**，这样**网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里**，此过程**不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区**中，这样就减少了一次数据拷贝；

![preview](https://pic2.zhimg.com/v2-dc405f1eb057217aee8820b6d3e340fd_r.jpg)

### 优化四：splice 方式

splice系统调用是 Linux 在 2.6 版本引入的，其不需要硬件支持，并且不再限定于 socket上，实现两个普通文件之间的数据零拷贝。

splice 系统调用可以**在内核缓冲区和 socket 缓冲区之间建立管道来传输数据**，避免了两者之间的 CPU 拷贝操作。

![preview](https://pic4.zhimg.com/v2-558c6409bac4096d4412375898eaa1e3_r.jpg)

> 管道是 Linux 中很重要的一种通信方式,是把一个程序的输出直接连接到另一个程序的输入,常说的管道多是指无名管道,无名管道只能用于具有亲缘关系的进程之间，这是它与有名管道的最大区别。  
> 有名管道叫 named pipe 或者 FIFO (先进先出)，可以用函数 mkfifo() 创建。

在 Linux 中，管道的实现并没有使用专门的数据结构，而是借助了文件系统的 file 结构和索引节点 inode。

**一个管道本质是一个 内存文件 ，同样使用 iNode 节点进行建模。** 这个文件有读写指针，分别代表着管道的二端。管道是通过将两个 file 结构指向同一个临时的索引节点，而这个索引节点又指向一个物理页面而实现的。


