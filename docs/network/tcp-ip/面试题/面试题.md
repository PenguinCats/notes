# 面试时答的不好的题目

## 负载均衡

负载均衡技术，用来在多个计算机（计算机集群）、网络连接、CPU、磁盘驱动器或其他资源中分配负载，以达到最佳化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。

可以通过 HTTP 重定向、DNS、反向代理、NAT等方式实现。

<img src="v2-7c9156e028659ea164d0d92e69c88383_1440w.jpg" alt="img" style="zoom: 67%;" />

<img src="v2-3b2dc25ad7ddf0ae86992c2972fabbd3_1440w.jpg" alt="img" style="zoom:67%;" />

<img src="v2-843cbee5c1f776922a73305ddd597f01_1440w.jpg" alt="img" style="zoom:67%;" />

<img src="v2-7c5cf88cb54a457d96a5fd1edee1d7c5_1440w.jpg" alt="img" style="zoom:67%;" />

负载均衡算法包括：轮询、随机、加权、hash（ip_hash：每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 的问题） 等。介绍三个常见的负载均衡器：

> 一文详解 LVS、Nginx 及 HAProxy 工作原理（ 附大图 ） - 地球的外星人君的文章 - 知乎 https://zhuanlan.zhihu.com/p/71690089

1. LVS

   LVS 是 Linux Virtual Server 的简称，也就是 Linux 虚拟服务器。现在 LVS 已经是 Linux 标准内核的一部分。

   **LVS 是四层负载均衡**，建立在传输层之上，LVS 支持 **TCP/UDP 的负载均衡**。因为 LVS 是四层负载均衡，因此它相对于其它高层负载均衡的解决办法（比如 DNS 域名轮流解析、应用层负载的调度、客户端的调度等）它的效率是非常高的。

   LVS 的转发主要通过修改 IP 地址（NAT 模式，分为源地址修改 SNAT 和目标地址修改 DNAT）、修改目标 MAC（DR 模式）来实现。

   1. NAT 模式：网络地址转换

      网络数据报的进出都要经过 LVS 的处理。LVS 需要作为 RS（真实服务器）的网关。当包到达 LVS 时，LVS 做目标地址转换（DNAT），将目标 IP 改为 RS 的 IP。RS 接收到包以后，仿佛是客户端直接发给它的一样。RS 处理完，返回响应时，源 IP 是 RS IP，目标 IP 是客户端的 IP。这时 RS 的包通过网关（LVS）中转，LVS 会做源地址转换（SNAT），将包的源地址改为 VIP

      <img src="v2-7cc1d4d17586ccfef91ddf2a8075617b_720w.jpg" alt="img" style="zoom:80%;" />

   2. DR 模式：直接路由

      DR 模式下需要 LVS 和 RS 集群绑定同一个 VIP（**RS 通过将 VIP 绑定在 loopback 实现**）。**与 NAT 的不同点在于：请求由 LVS 接受，由真实提供服务的服务器（Real Server，RS）直接返回给用户，返回的时候不经过 LVS。**这样可以避免负载均衡服务器网卡带宽成为瓶颈。因此，DR 模式具有较好的性能，也是目前大型网站使用最广泛的一种负载均衡手段。

      一个请求过来时，LVS 只需要将网络帧的 MAC 地址修改为某一台 RS 的 MAC，该包就会被转发到相应的 RS 处理，注意此时的源 IP 和目标 IP 都没变。RS 收到 LVS 转发来的包时，链路层发现 MAC 是自己的，到上面的网络层，发现 IP 也是自己的（loopback），于是这个包被合法地接受，RS 感知不到前面有 LVS 的存在。而当 RS 返回响应时，直接向源 IP（即用户的 IP）返回即可，不再经过 LVS。

      ![img](v2-9f1ae3b97930d796d81b619d34783d3a_720w.jpg)

2. Nginx

   Nginx 是一个强大的 Web 服务器软件，用于处理高并发的 HTTP 请求和作为反向代理服务器做负载均衡。

   相对于传统基于进程或线程的模型（Apache就采用这种模型）在处理并发连接时会为每一个连接建立一个单独的进程或线程，且在网络或者输入/输出操作时阻塞，Nginx 大量使用多路复用和事件通知方式，避免过多的上下文切换。

   Nginx 负载均衡主要是对七层网络通信模型中的**第七层应用层上的 http、https 进行支持**。Nginx 是以反向代理的方式进行负载均衡的。反向代理（Reverse Proxy）方式是指以代理服务器来接受 Internet 上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 Internet 上请求连接的客户端，此时代理服务器对外就表现为一个服务器。

3. HAproxy（没空研究）

   + 支持两种代理模式：TCP（四层）和HTTP（七层），支持虚拟主机
   + 能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作

## 从网卡到应用层，一个数据包经历了什么？

> 从网卡到应用层nginx，一个数据包经历了什么？ - linux的文章 - 知乎 https://zhuanlan.zhihu.com/p/423241850

### 从网卡到内存

+ 数据包从外面的网络进入物理网卡。如果目的地址不是该网卡，且该网卡没有开启混杂模式，该包会被网卡丢弃。

+ 网卡将数据包通过 DMA 的方式写入到指定的内存地址，该地址由网卡驱动分配并初始化。

  > 老的网卡可能不支持DMA，不过新的网卡一般都支持。

+ 网卡通过硬件中断（IRQ）通知 CPU，告诉它有数据来了
  +  CPU根据中断表，调用已经注册的中断函数，这个中断函数会调到驱动程序（NIC Driver）中相应的函数
  +  驱动先禁用网卡的中断，表示驱动程序已经知道内存中有数据了，告诉网卡下次再收到数据包直接写内存就可以了，不要再通知 CPU 了，这样可以提高效率，避免 CPU 不停的被中断。
  +  启动软中断。这步结束后，硬件中断处理函数就结束返回了。由于硬中断处理程序执行的过程中不能被中断，所以如果它执行时间过长，会导致CPU没法响应其它硬件的中断，于是内核引入软中断，这样可以将硬中断处理函数中耗时的部分移到软中断处理函数里面来慢慢处理。

### 内存-网络模块-协议栈

驱动程序将链路层数据校验解包等。上交给上层协议栈

### 网络层

+ 校验检查

+ 判断是要发给本机的吗？如果不是，进入转发流程
+ 如果是的话，解包 IP 层（可能涉及到 IP 切片的聚合），上交给上层（如 TCP UDP）

### 传输层

+ 校验检查
+ 查找该 package 的 **socket**。如果找不到，该 package 会被丢弃。接下来检查 socket 和 connection 的状态。
+ 如果 socket 和 connection 一切正常，调用 `tcp_prequeue` 使 package 从内核进入 user space，**放进 socket 的 receive queue**。然后 **socket 会被唤醒**，调用 system call，并最终调用 `tcp_recvmsg` 函数去从 socket recieve queue 中获取 segment。

### 应用层

+ 每当用户应用调用 `read` 或者 `recvfrom` 时，该调用会被映射为 `/net/socket.c` 中的 `sys_recv` 系统调用，并被转化为 `sys_recvfrom` 调用，然后调用 `sock_recgmsg` 函数。

+ **对 TCP 来说**，调用 `tcp_recvmsg`。该函数**从 socket buffer 中拷贝数据到 user buffer**。