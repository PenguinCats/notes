# 并发

## RWMutex 读写锁

You know that.

## Mutex 互斥锁

纯纯的互斥等待，没什么好说的

## Cond 条件变量

为了解决**等待**问题。例如生产者消费者模型中，生产者等待队列有空余，消费者等待队列中有产品。

如果**等待**问题依靠 mutex 不停的忙等检测（或者 sleep 再定时检测），会浪费系统资源，因此，希望能够以 event-driven 的方式，在 event 发生之前都一直保持阻塞状态。

即通过 wait() 让需要等待的 thread 进入 block 状态，调用 signal() 通知一个线程醒来或调用 broadcast() 让所有线程醒来。

### 为什么通常和锁一起使用？

以生产者消费者模型为例，因为涉及到并发，在**外部进行条件判断（通常借助某个变量）**以**决定是否需要进入 wait 状态**的时候，这个**外部判断所使用的变量应当要避免 data-race**（比如判断当前还有没有产品或者队列是不是满了），所以需要加锁。

因此，你可能写出这样的代码：

```go
cond.L.Lock()
if 不满足条件 : { // 这里应该用 for，涉及到所谓的虚假唤醒问题，一会再说。
    cond.wait()
}
唤醒之后再干别的事情
cond.L.UnLock()
```

需要注意的是，在将自己真正 block 之前，需要把锁释放掉，让其他线程有机会修改这些变量，满足条件的时候再换新该线程（比如生产者生产出来之后，唤醒消费者）。同时，自己唤醒之后还需要重新拿到这个锁，因为通常你接下来就要操作这个变量了（比如商品队列）。这里有一个需要注意的：wait 的正确顺序是：

1. 将自己加入阻塞队列
2. 释放锁
3. 等待唤醒
4. 获取锁

之所以要先将自己加入阻塞队列再释放锁，而不是先释放锁再加入队列，是为了防止：A 刚刚释放锁，应该发送 signal 的 B 线程立刻拿到了锁且执行完毕发送 signal，这样应该用于唤醒 A 的 signal 就丢失了，A 就一直被阻塞了。这种情况叫唤醒丢失。也就是说，释放锁的操作是在讲自己加入阻塞队列之后执行，所以要求用户传入这个锁，由 wait 内部完成，而不是由用户自己释放（不然用户还要先调用加入阻塞队列等操作再手动阻塞？）。

**需要强调的是，这个锁是为了保护外部变量的，而不是 cond 内部的执行逻辑。**

### 为什么条件判断应该用 `for` 而不是 `if`

刚刚的代码其实是有问题的，第 2 行不应该是 `if`，而应该是 `for`。

```go
cond.L.Lock()
for 不满足条件 : {
    cond.wait()
}
唤醒之后再干别的事情
cond.L.UnLock()
```

试想这样的情况，一个消费者被 block 了，一个生产者生产了一件商品，并且通过 signal 唤醒了消费者。**消费者 A 被唤醒之后，获取锁之前**，另一个醒着的消费者 B 迅速抢了这个锁，消耗了这个商品，然后释放锁。这样消费者 A 拿到这个锁的时候，发现没有商品可以消耗了。（除非此时所有的消费者都被 block 了，同一时间不存在两个醒着的消费者。但是这种状态不常见，你唤醒一个之后，它再进入下一次 block 之前，可能又有一个消费者被唤醒了）

**究其原因，是因为不能保证唤醒和获取锁的操作是原子的**，因此你获取锁之后，原来满足的条件可能又不满足了（商品被消耗了）。因此，你醒了之后，需要再判断一下条件，看看自己是不是真的可以开始操作。如果不可以的话，还要继续 wait。

**另外， 即使没有线程 broadcast 或者 signal 条件变量，wait也可能偶尔返回，这个叫虚假唤醒**。异常唤醒和多核处理器有关系，是底层实现的问题，所以试图在应用层解释都是没有意义的

> https://link.zhihu.com/?target=https%3A//en.m.wikipedia.org/wiki/Spurious_wakeup

### 给个 Go 和 CPP 写的生产者消费者的例子

#### go

> 其实我觉得下面的 consumer 和 producer 应该分开使用两个 sync.Cond，关联同一个 mutex。不然会出现生产者唤醒生产者，消费者唤醒消费者的憨憨情况。

```go
var MaxLen = 5
var cond *sync.Cond
var product []int

func consumer(id int) {
    for true {
        cond.L.Lock()
        for len(product) == 0 {
            cond.Wait()
        }
        fmt.Printf("consumer %d: use %d\n", id, product[0])
        product = product[1:]
        cond.L.Unlock()
        cond.Signal()
    }
}

func producer(id int) {
    for true {
        cond.L.Lock()
        for len(product) >= MaxLen {
            cond.Wait()
        }
        product = append(product, rand.Int() % 50)
        fmt.Printf("producer %d: produce %d\n", id, product[len(product)-1])
        cond.L.Unlock()
        cond.Signal()
    }
}

func main() {
    cond = sync.NewCond(&sync.Mutex{})
    product = make([]int, 0)

    for i := 0; i < 5; i++ {
        go consumer(i)
        go producer(i)
    }

    ch := make(chan int, 0)
    for range ch {
    }
}
```

> Tip: Go 直接用 `chan` 就可以了吧。自带缓冲区限制和阻塞唤醒功能，且并发安全。
> 
> ```go
> const MAXLEN = 5
> 
> func consumer(id int, ch chan int) {
>     for v := range ch {
>         fmt.Printf("consumer %d: use %d\n", id, v)
>     }
> }
> 
> func producer(id int, ch chan int) {
>     for true {
>         ch <- rand.Int() % 50
>     }
> }
> 
> func main() {
>     ch := make(chan int, MAXLEN)
> 
>     for i := 0; i < 5; i++ {
>         go consumer(i, ch)
>         go producer(i, ch)
>     }
> 
>     ch2 := make(chan int, 0)
>     for range ch2 {
>     }
> }
> ```

#### cpp

此处需要先补充一些 cpp 关于并发的知识。

+ pthread早于thread出现，本来是在类POSIX系统中用来多线程编程的，Windows原生不支持。std::thread 可以跨平台，它在 Linux 平台上不过是对 pthread 的一层包装。它大量使用 RAII。

+ std::mutex 的包装
  
  + 为了使用 RAII 机制，防止锁未正常释放，使用一些包装机制保证其自动 unlock
    
    + lock_guard
      
      会在 lock_guard 构造函数里加锁，在析构函数里解锁。
      
      虽然 lock_guard 挺好用的，但是有个很大的缺陷：lock_guard 在析构的时候一定会解锁，也没有中途解锁的功能。如果这个定义域范围很大的话，那么锁的粒度就很大，很大程序上会影响效率。
      
      ```c++
      std::mutex mtx;
      void func() {
          lock_guard<mutex> guard(mtx);
          // do some thing
      }
      ```
    
    + unique_lock
      
      为了解决 lock_guard 锁的粒度过大的原因，unique_lock 就出现了。这个会在构造函数加锁，然后可以利用 unique.unlock() 来解锁。
      
      析构的时候会判断当前锁的状态来决定是否解锁，如果当前状态已经是解锁状态了，那么就不会再次解锁，而如果当前状态是加锁状态，就会自动调用 unique.unlock() 来解锁。
      
      肯定是有代价的，unique_lock 内部会维护一个锁的状态，所以在效率上肯定会比 lock_guard 慢。
      
      ```c++
      std::mutex mtx;
      void func() {
          unique_lock<mutex> unique(mt);
          // do some thing
          unique.unlock();
          // do some thing
      }
      ```

+ std::shared_mutex

```c++
const int MAX_LEN = 5;

queue<int> q;
mutex mtx;
condition_variable cv_consumer;
condition_variable cv_producer;

void consumer(int id) {
    while (true) {
        unique_lock<mutex> lck(mtx);
        while (q.empty()) {
            cv_consumer.wait(lck);
        }
        cout << "consumer " + to_string(id) + ": use " + to_string(q.front()) << endl;
        q.pop();
        lck.unlock();
        cv_producer.notify_one();
    }
}

void producer(int id) {
    while (true) {
        unique_lock<mutex> lck(mtx);
        while (q.size() >= MAX_LEN) {
            cv_producer.wait(lck);
        }
        q.push(rand() % 50);
        cout << "producer " + to_string(id) + ": produce " + to_string(q.back()) << endl;
        lck.unlock();
        cv_consumer.notify_one();
    }
}

int main() {
    vector<std::thread> consumers;
    vector<std::thread> producers;
    for (int i = 0; i < 5; ++i) {
        consumers.emplace_back(consumer, i);
        producers.emplace_back(producer, i);
    }
    for (int i = 0; i < 5; ++i) {
        consumers[i].join();
        producers[i].join();
    }

    return 0;
}
```

## Semaphone

信号量其实是利用条件变量进行了封装，里面多了个计数器， 并以这个计数器的值作为是否阻塞的唯一依据，这个计数器的值通常代表了可用资源的数目。

可以用 cond 和 mutex 封装出一个 semaphone。但是好像据说 go 里面， mutex 使用大小限制为 1 的系统 semaphone 实现的？只不过没开放？

自己实现：

```c++
class Semaphore
{
public:
    Semaphore(long count = 0) : count(count) {}
    //V操作，唤醒
    void signal()
    {
        unique_lock<mutex> unique(mt);
        ++count;
        if (count <= 0)
            cond.notify_one();
    }
    //P操作，阻塞
    void wait()
    {
        unique_lock<mutex> unique(mt);
        --count;
        if (count < 0)
            cond.wait(unique);
    }

private:
    mutex mt;
    condition_variable cond;
    long count;
};
```

## atomic

```c++
atomic_int total(0);
```

对 total 的操作是原子的。

# Thread join() detach()

# 线程池、协程池

> 求推荐一个高性能的C++的线程池？ - CPP加油站的回答 - 知乎
> https://www.zhihu.com/question/457266231/answer/2593668301

## 为什么会有线程池，到底解决了什么问题

1. 减少线程的创建与销毁（线程的角度）

2. `异步解耦`的作用（设计的角度）
   
   以nginx为例，一秒几万的请求，速度很快。如果在其中加一个日志，那么qps一下子就掉下来了，因为每请求一次就需要落盘一次，那么整个服务器的性能就下降。我们可以引入一个线程池，把日志这个任务抛给线程池，对于主循环来说，就只抛任务即可，这样就可以大大提升主线程的效率。这就是线程池异步解耦的作用

> 错误理解：要使用线程就从线程池里面拿一个线程出来使用，用完再返回给线程池。这种理解是连接池的概念。
> 
> 正确理解：而线程池是多个线程去任务队列取任务，竞争任务。
> 
> ```cpp
> while(true){
>     get_task();
>     task->func();
> }
> ```

## 线程池至少应该有哪些 API 和组件

线程池应该提供哪些api。

1. 线程池的初始化(创建) init/create
2. 往池里面抛任务push_task
3. 线程池的销毁 deinit/destroy

应该有哪些组件？

1. 执行队列 （一组 pthread）

2. 任务队列（一组 task）

3. 池管理组件（例如 不会出现一个任务同时被多个线程处理的情况）

### C++ 的线程池

以 boost::asio 线程池为例

```cpp
void my_task()
{
  ...
}

...

// Launch the pool with four threads.
boost::asio::thread_pool pool(4);

// Submit a function to the pool.
boost::asio::post(pool, my_task);

// Submit a lambda object to the pool.
boost::asio::post(pool,
    []()
    {
      ...
    });

// Wait for all tasks in the pool to complete.
pool.join();
```

### Golang 有必要搞协程池吗

池化技术本来是用来复用提升性能的。goroutine的开销极小，不需要通过压榨goroutine的复用来进行提升性能。

但是根据场景的不同，有些人会把池子拿来做限流、限制并发等操作，这个时候是需要的。在性能非常严苛的场景下，为了避免过多的调度开销，可以考虑池化。

不过你非要用的话，其实也有 [ants/README_ZH.md at master · panjf2000/ants · GitHub](https://github.com/panjf2000/ants/blob/master/README_ZH.md)

```go
func demoFunc() {
    time.Sleep(10 * time.Millisecond)
    fmt.Println("Hello World!")
}

func main() {
    defer ants.Release()

    runTimes := 1000

    // Use the common pool.
    var wg sync.WaitGroup
    syncCalculateSum := func() {
        demoFunc()
        wg.Done()
    }
    for i := 0; i < runTimes; i++ {
        wg.Add(1)
        _ = ants.Submit(syncCalculateSum)
    }
    wg.Wait()
    fmt.Printf("running goroutines: %d\n", ants.Running())
    fmt.Printf("finish all tasks.\n")
}
```
